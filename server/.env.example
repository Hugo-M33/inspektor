# Ollama Configuration
# For local development with Docker Compose:
OLLAMA_BASE_URL=http://localhost:11434
# For remote Ollama server (see deployment/remote-ollama/SETUP.md):
# OLLAMA_BASE_URL=https://your-server.com/ollama

# Model Selection (choose based on your needs)
# Development (fast, small): llama3.2:1b (~1GB, 2GB RAM)
# Balanced: mistral:7b (~4GB, 8GB RAM)
# Production: mistral:7b or larger
OLLAMA_MODEL=llama3.2:1b

# Server Configuration
HOST=127.0.0.1
PORT=8000
